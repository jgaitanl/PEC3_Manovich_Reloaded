# ![foto1](https://www.timelooper.com/images/exhibition-design-home/museum_solutions_1.jpg)**PEC3 - Manovich Reloaded**

**Autor:**  Javier Gaitán Larrubia

**Año Lectivo: 2024-25**   

**Repositorio: <https://github.com/tuusuario/PEC3_Manovich_Reloaded>**

[](https://github.com/tuusuario/PEC3_Manovich_Reloaded)

-----
# **Introducción**
En su obra *El software toma el mando* , Lev Manovich analiza cómo la creciente centralidad del software ha transformado radicalmente los medios tradicionales, dando lugar a nuevos paradigmas culturales definidos por la **hibridación, la modularidad, la automatización, la variabilidad y la transcodificación** . Según el autor,

` `**“ *el software no solo modela la producción y distribución de medios, sino también cómo pensamos, nos comunicamos y percibimos el mundo* ” (Manovich, 2013)."** 

Esta afirmación destaca la capacidad del software para reconfigurar tanto la infraestructura técnica como la experiencia humana asociada a los medios.

Partiendo de estos principios, en este ejercicio se presentan dos ejemplos contemporáneos que ilustran claramente esta evolución en la cultura digital: **Google Lens** y **Timelooper** . Ambos casos evidencian no solo la fusión de distintos medios y disciplinas —como la fotografía, la geolocalización, la inteligencia artificial o la Realidad aumentada —, sino que también reflejan cómo **el software redefine nuestras prácticas culturales cotidianas** . Estas herramientas tecnológicas proponen nuevos modos de **percepción** , **interacción** y **memoria** , en los que lo físico y lo digital convergen continuamente, dando lugar a una experiencia mediática profundamente híbrida y transcodificada.

-------------------------------------------
<p align="center">
  <h2>Ejemplo 1 de Hibridación: Google Lens</h2><br>
  <img src="https://geeksroom.com/wp-content/uploads/2021/10/Google-Lens-Logo.jpg" width="200">
</p>

**Google Lens** es una aplicación desarrollada por ***Google*** que permite **interpretar el mundo visual** mediante tecnologías avanzadas de **inteligencia artificial** y **machine learning**. A través de la cámara de un dispositivo —ya sea un teléfono móvil, una tablet o un iPad—, el usuario puede apuntar hacia cualquier objeto, texto o paisaje, y recibir información instantánea: reconocimiento de objetos, traducción de textos en tiempo real, identificación de especies animales o vegetales, escaneo de códigos QR, sugerencias de compra en tiendas online, entre muchas otras funciones.

![](Aspose.Words.04e06d8a-bf6c-420f-bbfb-4c5683cac3d3.003.jpeg)

`                                                                                          `*Ejemplo de busqueda de información sobre una imagen real*

Esta experiencia representa mucho más que un simple avance tecnológico; implica una profunda ***fusión entre hardware y software***: la cámara del dispositivo se convierte en una extensión de la percepción humana, mientras que el procesamiento mediante inteligencia artificial redefine la forma en que **vemos**, **interpretamos** y **navegamos** por el entorno. Basta con enfocar la cámara para acceder a una capa de datos que antes estaba oculta a la percepción ordinaria.

**Análisis desde los principios de Manovich:**

- **Modularidad:** Google Lens está construido a partir de una arquitectura modular, donde los diferentes sistemas trabajan en paralelo: visión computacional, reconocimiento óptico de caracteres (OCR), motores de búsqueda semántica, traducción automática, e-commerce, entre otros servicios. Cada módulo puede actualizarse o ampliarse sin necesidad de reconstruir la plataforma completa.
- **Automatización:** El proceso de captura, análisis y respuesta ocurre de forma casi instantánea y sin intervención consciente del usuario. La automatización elimina la necesidad de buscar información manualmente o directa, externalizando procesos básicos como identificar, traducir o memorizar.
- **Variabilidad:** La información ofrecida por Lens no es estática ni universal; varía en función de múltiples factores como la localización geográfica, el idioma configurado, el historial de búsquedas del usuario, y el contexto cultural. Así, cada experiencia de uso es única y personalizada.
- **Transcodificación:** Los datos físicos capturados por la cámara (imágenes de objetos, textos, rostros, monumentos) se convierten en **información digital manipulable**. Este cambio de formato permite que el mundo físico sea procesado, categorizado, analizado y recombinado según lógicas computacionales.

![](Aspose.Words.04e06d8a-bf6c-420f-bbfb-4c5683cac3d3.004.png)

*Ejemplo de busqueda de negocio con google lens*

**Google Lens**, por tanto, transforma la cámara de los dispositivos móviles en una **potente interfaz de conocimiento e interacción**. Ya no utilizamos la cámara solo para capturar imágenes; la utilizamos para acceder a **capas invisibles de significado**, para **traducir signos** del mundo físico en información digital accesible, y para **tomar decisiones** basadas en datos interpretados automáticamente. Esta reconfiguración redefine radicalmente nuestra manera de **percibir, comprender y actuar** en el entorno cotidiano, en línea con lo que Lev Manovich describe como la emergencia de una cultura digital completamente **mediada por el software**.

Enlace video de youtube de como funciona Google Lens [Descrubre mas sobre Google Lens](https://www.youtube.com/watch?v=7yOUpAvckao)

Enlace oficial: <https://lens.google/>

-----
#
# **Ejemplo 2 Hibridación: Timelooper ![](Aspose.Words.04e06d8a-bf6c-420f-bbfb-4c5683cac3d3.005.jpeg)**

**Timelooper** es una innovadora plataforma digital que combina tecnologías de **realidad virtual (VR)** y **realidad aumentada (AR)** para ofrecer una experiencia transformadora de inmersión histórica. Su propuesta no se limita a complementar el aprendizaje tradicional o el turismo cultural, sino que lo modifica por completo, permitiendo a los usuarios **revivir eventos históricos significativos desde la ubicación exacta en que ocurrieron**. A través de un visor VR o incluso desde la pantalla de un teléfono móvil, el entorno físico actual se convierte en una ventana al pasado, superponiendo recreaciones tridimensionales, paisajes sonoros y animaciones en tiempo real que reconstruyen momentos emblemáticos de la historia.

![](Aspose.Words.04e06d8a-bf6c-420f-bbfb-4c5683cac3d3.006.jpeg)

Lo más destacable de esta aplicación es su capacidad para **generar una conexión emocional, espacial y sensorial con los hechos históricos**. La experiencia no es pasiva ni distante: el usuario se encuentra “dentro” del acontecimiento, participando de una narrativa envolvente donde se intercambian las fronteras entre espectador y protagonista. De este modo, la ciudad, el monumento o el espacio urbano dejan de ser meros escenarios para convertirse en auténticos **teatros del tiempo**, donde el pasado cobra vida mediante capas digitales interactivas. Este enfoque convierte a Timelooper en mucho más que una herramienta educativa o turística: es un medio narrativo que **fusiona la historia con la vivencia directa**, marcando un punto de inflexión en la forma en que accedemos al conocimiento.

Desde el punto de vista conceptual, esta propuesta responde a las lógicas de los **nuevos medios digitales**, particularmente a lo que ***Lev Manovich identifica como principios fundamentales: modularidad, automatización, variabilidad y transcodificación***. Cada escena histórica es un módulo independiente; el sistema automatiza su activación mediante geolocalización; la experiencia varía según el dispositivo, el idioma o el tipo de acceso; y finalmente, los datos históricos se traducen en **experiencias multimedia interactivas** que transforman nuestra percepción del espacio y del tiempo.

Además, Timelooper se inscribe dentro del concepto de **remediación** propuesto por Bolter y Grusin, al apropiarse de formas tradicionales de representación (el documental, la recreación museográfica, el tour guiado) y adaptarlas a una lógica interactiva y multisensorial. Así, se establece una nueva forma de consumir y producir contenido histórico, donde lo digital no reemplaza al mundo físico, sino que **lo expande, lo resignifica y lo recontextualiza**.

La apuesta va incluso más allá de lo tecnológico: propone una forma de **reencantar la historia**, de devolverle cuerpo, emoción y presencia. En una época en la que el conocimiento tiende a ser fragmentado, acelerado y abstracto, esta plataforma recupera la dimensión **vivencial** del saber histórico. El usuario no solo “aprende” sobre el pasado, sino que lo **experimenta**, lo **recorre** y, en cierto modo, **lo habita**.

En definitiva, este dispositivo representa un claro ejemplo del potencial de las tecnologías emergentes para **transformar nuestra relación con la memoria cultural**, permitiéndonos no solo recordar, sino también vivir el pasado de forma activa, inmersiva y significativa.

![](Aspose.Words.04e06d8a-bf6c-420f-bbfb-4c5683cac3d3.007.png)

https://dc-cdn.s3-ap-southeast-1.amazonaws.com/dc-Cover-07fio02l78osm7f7gh5v8ar9u1-20160314193556.Medi.jpeg

### **Análisis desde los principios de Manovich:**
- **Modularidad: Cada recreación histórica dentro de Timelooper es una unidad autónoma, que puede ser accedida de forma independiente. Estas escenas están organizadas como módulos digitales reutilizables, lo que permite a los desarrolladores y curadores de contenido construir nuevas experiencias sumando o reordenando elementos sin modificar el sistema entero.**
- **Automatización: La aplicación usa funciones automatizadas como la geolocalización para detectar en qué lugar se encuentra el usuario y sincronizar automáticamente la escena histórica correspondiente. Esto elimina la necesidad de selección manual, haciendo que el sistema reaccione inteligentemente al contexto físico del usuario.**
- **Variabilidad:  ofrece múltiples formas de interacción con su contenido: puede ser utilizado con o sin visor VR, está disponible en varios idiomas, y presenta diferencias entre las versiones gratuitas y premium. Esta adaptabilidad refleja el principio de variabilidad de Manovich, ya que una misma base de datos puede generar múltiples experiencias personalizadas.**
- **Transcodificación: El contenido digital transforma la percepción del espacio físico real (la ciudad, la calle, el sitio histórico) en una interfaz narrativa. La experiencia del usuario es un híbrido entre lo material y lo simbólico: la ciudad deja de ser solo un lugar físicoy se convierte en una superficie sobre la que se proyectan capas de memoria colectiva digitalizadas.**

![](Aspose.Words.04e06d8a-bf6c-420f-bbfb-4c5683cac3d3.008.jpeg)

[Como Timelooper te transportara al pasado](https://www.youtube.com/watch?v=ifnIF0HUo0M)[](https://www.youtube.com/watch?v=ifnIF0HUo0M)

[](https://www.youtube.com/watch?v=ifnIF0HUo0M)

Enlace oficial: <https://timelooper.com/>

-----
# **CONCLUSIONES** 
Los casos de Google Lens y Timelooper ilustran de manera contundente cómo el software no solo amplifica las capacidades de los medios tradicionales, sino que los reconfigura y los adapta profundamente, transformando también nuestras formas de percibir e interactuar con la realidad, aplicaciones adaptadas a las nuevas tendencias y necesidades.

Lejos de tratarse de una superposición superficial, la hibridación entre lo físico y lo digital implica una transformación estructural de la percepción, la memoria, el conocimiento y la experiencia del espacio. En el contexto de la cultura digital contemporánea, estas dimensiones ya no pueden entenderse como independientes: el software actúa como un tejido integrador que genera nuevos lenguajes, narrativas emergentes y modos inéditos de vivir y comprender el mundo.

-----
# **Referencias bibliográficas**
- Manovich, L. (2013). *El software toma el mando* . Editorial UOC.
- Bolter, J. D., & Grusin, R. (1999). *Remediation: Understanding New Media*. MIT Press.
- Google Lens. (2025).<https://lens.google/>
- Timelooper. (sin fecha). Recuperado en abril de 2025 de <https://timelooper.com/>
- Xataka. (Dakota del Norte). Artículos sobre realidad aumentada y reconocimiento de imágenes. Obtenido de <https://www.xataka.com/>
- Awwwards. (sf). Inspiración para la innovación digital. Recuperado de <https://www.awwwards.com/>
- [https://es.m.wikipedia.org/wiki/Archivo:Google\_Lens\_Icon.svg](https://es.m.wikipedia.org/wiki/Archivo:Google%5C_Lens%5C_Icon.svg)
- Video de Youtube [Descrubre mas sobre Google Lens](https://www.youtube.com/watch?v=7yOUpAvckao)
- Video de Youtube [Como Timelooper te transportara al pasado](https://www.youtube.com/watch?v=ifnIF0HUo0M)
-----
# **Licencia**
Este trabajo está publicado bajo una licencia [Creative Commons CC BY-SA 4.0](https://creativecommons.org/licenses/by-sa/4.0/).
